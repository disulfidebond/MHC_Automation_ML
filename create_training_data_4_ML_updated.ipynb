{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "# Workflow is stop-start at best and urgently needs to be revisited, to be standardized, and to be automated\n",
    "# In current form:\n",
    "# # Run function on existing Excel spreadsheet\n",
    "# # spreadsheet MUST be tab-delimited; this was added ad-hoc to fix problems with commas\n",
    "# # note that there are other better solutions, such as using read.csv()\n",
    "# # a column of hash '#' marks MUST be added at the end of samples; this was added ad-hoc due to a parsing conflict\n",
    "# # other solutions exist, such as parsing by line or parsing by column count\n",
    "# # Then, the data will be a pandas dataframe, which will be output to a csv file.\n",
    "# # This csv file must be manually parsed with two steps:\n",
    "# # # remove duplicate marker \"_i\" where \"i\" is an incrementer; this obviously can be modified multiple ways\n",
    "# # # Scan the file to rename duplicated Haplotype entries (but DO NOT MERGE THE ENTRIES--having replicated entries is critical!), for example \"A001-A008\" is the same as \"A008-A001\"; again, this obviously can be modified multiple ways\n",
    "# # This output is ready for training, provided it is in the format of Haplotypes as the rownames and alleles as the column names across the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def openFileAsList(f):\n",
    "    l = []\n",
    "    with open(f, 'r') as fOpen:\n",
    "        for i in fOpen:\n",
    "            i = i.rstrip('\\r\\n')\n",
    "            l.append(i)\n",
    "    return l\n",
    "\n",
    "def openAndParse(f):\n",
    "    hapA = []\n",
    "    hapB = []\n",
    "    hapList = []\n",
    "    with open(f, 'r') as fOpen:\n",
    "        importData = False\n",
    "        for i in fOpen:\n",
    "            if importData:\n",
    "                # required for pivot tables with A_01... as well as Mamu_A_01...\n",
    "                m = re.search('Mamu', i)\n",
    "                iString = i\n",
    "                if not m:\n",
    "                    iString = 'Mamu_' + i\n",
    "                m = re.search('|', i)\n",
    "                pLine = []\n",
    "                if m:\n",
    "                    pLineParsed = iString.split('\\t')\n",
    "                    pLine = iString.split('#')\n",
    "                    pLineD = pLine[0].split('\\t')\n",
    "                    pLineName = pLineD[0].split('|')\n",
    "                    pLineResult = []\n",
    "                    pLineResult.append(pLineName[0])\n",
    "                    pLineResult = pLineResult + pLineD[1:]\n",
    "                    hapList.append(pLineResult)\n",
    "                else:\n",
    "                    pLine = iString.split('#')\n",
    "                    pLineD = pLine[0].split('\\t')\n",
    "                    hapList.append(pLineD)\n",
    "            else:\n",
    "                # i = i.rstrip('\\r\\n')\n",
    "                # m = re.search('run_id', i)\n",
    "                m = re.search('Comments', i)\n",
    "                m2 = re.search('MHC', i)\n",
    "                if m:\n",
    "                    importData = True\n",
    "                    continue\n",
    "                if m2:\n",
    "                    iParsed = re.sub('\".*\"', '-', i) # removes error entries from consideration\n",
    "                    # the above parsing will fail on some files, unknown why, probably encoding.  Fix in TextEdit.\n",
    "                    p = iParsed.split('-')\n",
    "                    pLine = iParsed.split('#')\n",
    "                    pLineD = pLine[0].split('\\t')\n",
    "                    if p[1][0] == 'A':\n",
    "                        hapA.append(pLineD[1:])\n",
    "                    if p[1][0] == 'B':\n",
    "                        hapB.append(pLineD[1:])\n",
    "    return ((hapA, hapB), hapList)\n",
    "\n",
    "def mapAndIndex(l):\n",
    "    retList = []\n",
    "    lMap = list(map(lambda x: x!= '', l))\n",
    "    for a,b in enumerate(lMap):\n",
    "        if b:\n",
    "            retList.append(a)\n",
    "    return retList\n",
    "\n",
    "def mapAndIndexWithInt(l):\n",
    "    retList = []\n",
    "    lMap = list(map(lambda x: x!= '', l))\n",
    "    for a,b in enumerate(lMap):\n",
    "        if b:\n",
    "            retList.append(a)\n",
    "    return retList\n",
    "\n",
    "def parseAndMerge(parseList, mergeList):\n",
    "    mergeReturnList = []\n",
    "    for tItem in mergeList:\n",
    "        mergeReturnList.append((tItem, []))\n",
    "    for x in range(0, len(parseList)):\n",
    "        hList = parseList[x]\n",
    "        hValue = hList[0]\n",
    "        hList = hList[1:]\n",
    "        # python copies by reference:\n",
    "        # do not modify list mid-loop or unpredictable things may occur\n",
    "        hListWithIndexes = mapAndIndex(hList)\n",
    "        for idx in hListWithIndexes:\n",
    "            mergeReturnList[idx][1].append(hValue)\n",
    "    return mergeReturnList\n",
    "def parseAlleleToList(alleleList):\n",
    "    # deprecated\n",
    "    rListAsList = []\n",
    "    for itm in alleleList:\n",
    "        s = itm.split('_')\n",
    "        s_tmp = '_'.join(s[1:])\n",
    "        rListAsList.append(s_tmp)\n",
    "    return rListAsList\n",
    "def parseAlleleString(alleleList):\n",
    "    # deprecated\n",
    "    rListAsString = ''\n",
    "    for itm in alleleList:\n",
    "        s = itm.split('_')\n",
    "        s_tmp = '_'.join(s[1:])\n",
    "        rListAsString += s_tmp + '\\n'\n",
    "    rListAsString = rListAsString[:-1]\n",
    "    return rListAsString\n",
    "def parseAllelesToString(alleleList):\n",
    "    rListAsString = ''\n",
    "    print(alleleList)\n",
    "    for itm in alleleList:\n",
    "        s = str(itm[0]) + ',' + str(itm[1])\n",
    "        rListAsString += s + '\\n'\n",
    "    return rListAsString\n",
    "\n",
    "def parseAlleleStringPandas(alleleList, allAlleles):\n",
    "    alleleTupleList = []\n",
    "    for a in allAlleles:\n",
    "        if a not in alleleList:\n",
    "            # alleleTupleList.append((a, 0))\n",
    "            alleleTupleList.append(0)\n",
    "        else:\n",
    "            # alleleTupleList.append((a, 1))\n",
    "            alleleTupleList.append(1)\n",
    "    return alleleTupleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAlleleList = openFileAsList('allele_names.txt')\n",
    "hapAandB2 = openAndParse('20929_pivot.txt')\n",
    "hapA = hapAandB2[0][0]\n",
    "hapB = hapAandB2[0][1]\n",
    "hapResults = hapAandB2[1]\n",
    "\n",
    "      \n",
    "hapResultsA_Tuple = []\n",
    "hapResultsB_Tuple = []\n",
    "\n",
    "for x in range(0, len(hapA[0])):\n",
    "    hapResultsA_Tuple.append((hapA[0][x], hapA[1][x]))\n",
    "for x in range(0, len(hapB[0])):\n",
    "    hapResultsB_Tuple.append((hapB[0][x], hapB[1][x]))\n",
    "hResultsList = []\n",
    "hapResultsA_TupleList = parseAndMerge(hapResults, hapResultsA_Tuple)\n",
    "hapResultsB_TupleList = parseAndMerge(hapResults, hapResultsB_Tuple)\n",
    "alleleDF = None\n",
    "columns = []\n",
    "for nItem in hapResultsB_TupleList:\n",
    "    # print('\\n')\n",
    "    if nItem[0][0] == nItem[0][1]:\n",
    "        columns.append(nItem[0][0])\n",
    "    else:\n",
    "        cString = str(nItem[0][0] + '-' + nItem[0][1])\n",
    "        columns.append(cString)\n",
    "columns = columns[:-1]\n",
    "iterValue = 1\n",
    "for tItem in hapResultsB_TupleList:\n",
    "    cString = str(tItem[0][0] + '-' + tItem[0][1])\n",
    "    # the step below is deprecated.\n",
    "    # lOutput = parseAlleleToList(tItem[1])\n",
    "    lOutput = parseAlleleToList(tItem[1])\n",
    "    tupleOutput = parseAlleleStringPandas(lOutput, allAlleleList)\n",
    "    if alleleDF is None:\n",
    "        pdDict = dict()\n",
    "        pdDict[cString] = tupleOutput\n",
    "        alleleDF = pd.DataFrame.from_dict(pdDict, orient='index').transpose()\n",
    "        alleleDF.index=allAlleleList\n",
    "        alleleDF.index.name = 'allele'\n",
    "    else:\n",
    "        # print('\\n')\n",
    "        if tItem[0][0] == tItem[0][1]:\n",
    "            # print(tItem[0][0])\n",
    "            cString = tItem[0][0]\n",
    "            pdDict = dict()\n",
    "            # if cString in alleleDF:\n",
    "            #    cString = cString + '_' + str(iterValue)\n",
    "            #    iterValue += 1\n",
    "            pdDict[cString] = tupleOutput\n",
    "            alleleDFnew = pd.DataFrame.from_dict(pdDict, orient='index').transpose()\n",
    "            alleleDFnew.index=allAlleleList\n",
    "            alleleDFnew.index.name = 'allele'\n",
    "            alleleDFres = pd.concat([alleleDF, alleleDFnew], axis=1, join_axes=[alleleDF.index])\n",
    "            alleleDF = alleleDFres\n",
    "            # sOutput = parseAllelesToString(tupleOutput)\n",
    "            # print(sOutput)\n",
    "        else:\n",
    "            # cString = str(tItem[0][0] + '-' + tItem[0][1])\n",
    "            cStringRev = str(tItem[0][1] + '-' + tItem[0][0])\n",
    "            if cStringRev in alleleDF:\n",
    "                cString = cStringRev\n",
    "            pdDict = dict()\n",
    "            cStringRev = str(tItem[0][1] + '-' + tItem[0][0])\n",
    "            pdDict[cString] = tupleOutput\n",
    "            alleleDFnew = pd.DataFrame.from_dict(pdDict, orient='index').transpose()\n",
    "            alleleDFnew.index=allAlleleList\n",
    "            alleleDFnew.index.name = 'allele'\n",
    "            alleleDFres = pd.concat([alleleDF, alleleDFnew], axis=1, join_axes=[alleleDF.index])\n",
    "            alleleDF = alleleDFres\n",
    "alleleDF.to_csv('allele_df-20929.hapB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hel'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Hello World'\n",
    "s[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
