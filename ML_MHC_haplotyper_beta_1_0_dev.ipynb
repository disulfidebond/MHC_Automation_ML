{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: Follow the instructions provided in each step, or in the output from a cell \n",
    "Step 1\n",
    "* Make sure the python notebook and the pivot table Excel file are in the **same** folder on your computer.\n",
    "* Enter the name of the pivot table in the next cell, then press the 'run' button above.\n",
    "* The python notebook will give you a preview of what will be used in the analysis beneath the cell after you press the run button.  \n",
    "  * Scan the row names to verify that they are the same as in the Excel sheet that you want ot use.  If they are, skip the following cells and proceed to Step 2.\n",
    "* Otherwise, follow the instructions in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivot_table = '20411_Felber1-2_MHC-I_Haplotypes_23Mar18.xlsx' # enter name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Developer Comment: JRC\n",
    "# see dev_comments3_beta_1_0.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Developer Comment: JRC\n",
    "# Remaining ToDo:\n",
    "# # add in MHC-B to ML module\n",
    "# # remove all developer comments from beta version\n",
    "# # writeup features that will be added (replace patch, write into pivot_table and not a csv file)\n",
    "# # final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please examine the values that are listed from column 1 of the file.\n",
      "If they are correct or what you would expect, click the next cell and press Run.\n",
      "Otherwise, double check the filename and try again, or in the next cell,\n",
      "specify the file type and the Excel sheet name, and then click Run.\n",
      "\n",
      "\n",
      "\n",
      "Animal ID\n",
      "\n",
      "# Reads Evaluated\n",
      "\n",
      "# Reads Identified\n",
      "\n",
      "% Unknown\n",
      "\n",
      "Mamu-A Haplotype 1\n",
      "\n",
      "Mamu-A Haplotype 2\n",
      "\n",
      "Mamu-B Haplotype 1\n",
      "\n",
      "Mamu-B Haplotype 2\n",
      "\n",
      "Comments\n",
      "\n",
      "Processed Pivot Table\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#PRAGMA MARK: parseInputData \n",
    "# import input data, then parse into Pandas DataFrame\n",
    "def parseExcelWithPandas(fName, excelFileP):\n",
    "    eSheetData = ''\n",
    "    dfs = {sheet_name: excelFileP.parse(sheet_name)\n",
    "      for sheet_name in excelFileP.sheet_names}\n",
    "    if not fName:\n",
    "        sheetCount = -1\n",
    "        for s in dfs:\n",
    "            sheetCount += 1\n",
    "            m = re.search('pivot', s)\n",
    "            m2 = re.search('MiSeq', s)\n",
    "            if m:\n",
    "                eSheetDataInt = pd.ExcelFile(pivot_table)\n",
    "                eSheetData = eSheetDataInt.parse(sheetCount)\n",
    "            elif m2:\n",
    "                eSheetDataInt = pd.ExcelFile(pivot_table)\n",
    "                eSheetData = eSheetDataInt.parse(sheetCount)\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        for s in dfs:\n",
    "            m = re.search(fName, s) # case insensitive?\n",
    "            if m:\n",
    "                eSheetDataInt = pd.ExcelFile(pivot_table)\n",
    "                eSheetData = eSheetDataInt.parse(sheetCount)\n",
    "            else:\n",
    "                continue\n",
    "    return eSheetData\n",
    "\n",
    "def openFileAsList(f):\n",
    "    l = []\n",
    "    with open(f, 'r') as fOpen:\n",
    "        for i in fOpen:\n",
    "            i = i.rstrip('\\r\\n')\n",
    "            l.append(i)\n",
    "    return l\n",
    "\n",
    "def findColumnIdxStartStop(pdDF):\n",
    "    xCt = -1\n",
    "    xStart = -1\n",
    "    xStop = -1\n",
    "    foundInitialMatch = False\n",
    "    for x in excelSheetName.columns.values:\n",
    "        xCt += 1\n",
    "        if xCt == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if xCt < 10 and foundInitialMatch == False: # column idx will not be greater than 9\n",
    "                m = re.search('named', str(x))\n",
    "                if m:\n",
    "                    continue\n",
    "                else:\n",
    "                    foundInitialMatch = True\n",
    "                    xStart = xCt\n",
    "            else: \n",
    "                m = re.search('named', str(x))\n",
    "                if m:\n",
    "                    xStop = xCt\n",
    "                    break\n",
    "    return (xStart, xStop)\n",
    "\n",
    "def parsePandasDfRows(col1ListFromPdDf):\n",
    "    headers = True\n",
    "    mamuA_indices = []\n",
    "    mamuB_indices = []\n",
    "    skipIndices = []\n",
    "    genotypeList = []\n",
    "    for idx,val in enumerate(col1ListFromPdDf):\n",
    "        if headers:\n",
    "            m = re.search('Comment', str(val))\n",
    "            mA = re.search('Mamu-A', str(val))\n",
    "            mB = re.search('Mamu-B', str(val))\n",
    "            if m:\n",
    "                headers = False\n",
    "                skipIndices.append(idx)\n",
    "            elif mA:\n",
    "                mamuA_indices.append(idx)\n",
    "            elif mB:\n",
    "                mamuB_indices.append(idx)\n",
    "            else:\n",
    "                skipIndices.append(idx)\n",
    "        else:\n",
    "            m = re.search('Alleles', str(val))\n",
    "            if m:\n",
    "                skipIndices.append(idx)\n",
    "            elif type(val) is float:\n",
    "                skipIndices.append(idx)\n",
    "            else:\n",
    "                genotypeList.append(val)\n",
    "    return (skipIndices, mamuA_indices, mamuB_indices, genotypeList)\n",
    "'''\n",
    "def dataToPandasOneHot(d, pdDf, idxList):\n",
    "    if pdDf is None:\n",
    "        pdDf = pd.DataFrame({'genotypeValues': idxList})\n",
    "        pdDf.index = idxList\n",
    "        pdDf.index.name = 'genotype'\n",
    "        pdDfNew = pd.DataFrame.from_dict(d, orient='index').transpose()\n",
    "        pdDf.index = idxList\n",
    "        pdDf.index.name = 'genotype'\n",
    "        alleleDFres = pd.concat([pdDf, pdDfNew], axis=1, join_axes=[pdDf.index])\n",
    "        pdDf = alleleDFres\n",
    "    else:\n",
    "        alleleDFnew = pd.DataFrame.from_dict(d, orient='index').transpose()\n",
    "        alleleDFnew.index = idxList\n",
    "        alleleDFnew.index.name = 'genotype'\n",
    "        alleleDFres = pd.concat([pdDf, alleleDFnew], axis=1, join_axes=[pdDf.index])\n",
    "        pdDf = alleleDFres\n",
    "    print('DataFrame is')\n",
    "    print(pdDf)\n",
    "    time.sleep(5)\n",
    "    return pdDf\n",
    "\n",
    "'''\n",
    "def dataToPandasOneHot(d, pdDf, idxList):\n",
    "    if pdDf is None:\n",
    "        pdDf = pd.DataFrame.from_dict(d, orient='index').transpose()\n",
    "        pdDf.index = idxList\n",
    "        pdDf.index.name = 'genotype'\n",
    "    else:\n",
    "        alleleDFnew = pd.DataFrame.from_dict(d, orient='index').transpose()\n",
    "        alleleDFnew.index = idxList\n",
    "        alleleDFnew.index.name = 'genotype'\n",
    "        alleleDFres = pd.concat([pdDf, alleleDFnew], axis=1, join_axes=[pdDf.index])\n",
    "        pdDf = alleleDFres\n",
    "    return pdDf\n",
    "\n",
    "def parseIdxForMamuAMamuB(gList):\n",
    "    # parses genotype names from filtered genotype list\n",
    "    mamuA_nameIdxListCol1 = []\n",
    "    mamuB_nameIdxListCol1 = []\n",
    "    for idx, n in enumerate(gList):\n",
    "        m_MamuA = re.search('Mamu_A', str(n))\n",
    "        m_MamuB = re.search('Mamu_B', str(n))\n",
    "        if m_MamuA:\n",
    "            filterMamu = re.search('Mamu_AG', str(n))\n",
    "            if filterMamu:\n",
    "                continue\n",
    "            else:\n",
    "                mamuA_nameIdxListCol1.append(idx)\n",
    "        if m_MamuB:\n",
    "            mamuB_nameIdxListCol1.append(idx)\n",
    "    return (mamuA_nameIdxListCol1, mamuB_nameIdxListCol1)\n",
    "\n",
    "def parseGenotypeList(gList):\n",
    "    r = []\n",
    "    gListCheck = gList[0]\n",
    "    gListCheckedString = gListCheck.split('_')\n",
    "    gListItemToCheck = str(gListCheckedString[0])\n",
    "    m = re.match('\\d+', gListItemToCheck)\n",
    "    if m:\n",
    "        for g in gList:\n",
    "            if type(g) is float:\n",
    "                continue\n",
    "            else:\n",
    "                gString = g.split('_')\n",
    "                gStringAsList = gString[1:]\n",
    "                gStringAsString = '_'.join(gStringAsList)\n",
    "                r.append(gStringAsString)\n",
    "    else:\n",
    "        return None\n",
    "    return r\n",
    "    \n",
    "testFile = pd.ExcelFile(pivot_table)\n",
    "readyToProceed = False\n",
    "fName_none = ''\n",
    "dataAsPandas = ''\n",
    "excelSheetName = parseExcelWithPandas(fName_none, testFile)\n",
    "processedPivotTable = False\n",
    "if pivot_table:\n",
    "    if excelSheetName.empty:\n",
    "        print('The Excel sheet was found, but there was an error reading the Excel file.')\n",
    "        print('Please do one of the following:\\n\\nProceed to the next cell and attempt to enter the sheet_name value,\\n\\nor\\n\\nExport the file as a csv, start from the beginning of the python notebook,\\nchange the file name, and rerun all cells.\\nBe sure to specify the file type as csv in the cell below when you run it.')\n",
    "    else:\n",
    "        print('Please examine the values that are listed from column 1 of the file.')\n",
    "        print('If they are correct or what you would expect, click the next cell and press Run.')\n",
    "        print('Otherwise, double check the filename and try again, or in the next cell,\\nspecify the file type and the Excel sheet name, and then click Run.')\n",
    "        print('\\n\\n')\n",
    "        pdHeadersRowsCol1 = list(excelSheetName.iloc[1:10:,0])\n",
    "        for h in pdHeadersRowsCol1:\n",
    "            m = re.search('Animal ID', h)\n",
    "            if m:\n",
    "                processedPivotTable = True\n",
    "            print(h + '\\n')\n",
    "        if processedPivotTable:\n",
    "            print('Processed Pivot Table')\n",
    "        else:\n",
    "            print('raw pivot table')\n",
    "        readyToProceed = True\n",
    "else:\n",
    "    print('No pivot table was found. Please do the following: \\n1) check the filename and rerun the previous cell\\n2) if you have already rerun the previous cell and are seeing this message again, \\nproceed to the next cell and enter information for at least one of the following: ')\n",
    "    print('\\tfile_type: enter \\'csv\\' or \\'excel\\', depending on the file.')\n",
    "    print('\\tsheet_name: enter the sheet name for the excel spreadsheet or csv file')\n",
    "    print('Then run the next two cells.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRAGA MARK: structureData\n",
    "# create data structure for input data, training data\n",
    "def parseLabeledValues(l):\n",
    "    r = []\n",
    "    for i in l:\n",
    "        iSplit = i.split('-')\n",
    "        iSplitSorted = sorted(iSplit)\n",
    "        iSplitSortdString = '-'.join(iSplitSorted)\n",
    "        if iSplit[0] == iSplit[1]:\n",
    "            r.append(iSplit[0])\n",
    "        else:\n",
    "            r.append(iSplitSortdString)\n",
    "    return r\n",
    "\n",
    "def parseDataIntoPandasDF(rStartInt, rStopInt, mamuA_rows, mamuB_rows, skipMamuRowInts, excelSheetName, gListForIndex):\n",
    "    rRange = rStopInt - rStartInt\n",
    "    mamuA_alleleList = []\n",
    "    mamuB_alleleList = []\n",
    "    alleleDF_MamuA = None\n",
    "    alleleDF_MamuB = None\n",
    "    for x in range(rStart, rStop):\n",
    "        mamu_genotypes_oneHot = []\n",
    "        dfValue = excelSheetName.iloc[:,x]\n",
    "        # dfValueMerged = mergeDataFrameValues()\n",
    "        dfValue_MamuA_1 = dfValue.iloc[int(mamuA_rows[0])]\n",
    "        dfValue_MamuA_2 = dfValue.iloc[int(mamuA_rows[1])]\n",
    "        dfValue_MamuB_1 = dfValue.iloc[int(mamuB_rows[0])]\n",
    "        dfValue_MamuB_2 = dfValue.iloc[int(mamuB_rows[1])]\n",
    "        pdDict_MamuA = dict()\n",
    "        pdDict_MamuB = dict()\n",
    "        additionalValuesBool = False\n",
    "        for idx, row in dfValue.iteritems():\n",
    "            if idx not in skipMamuRowInts:\n",
    "                try:\n",
    "                    if math.isnan(row):\n",
    "                        mamu_genotypes_oneHot.append(0)\n",
    "                        continue\n",
    "                    else:\n",
    "                        mamu_genotypes_oneHot.append(1)\n",
    "                except TypeError:\n",
    "                    mamu_genotypes_oneHot.append(1)\n",
    "        pdDictKey_MamuA = str(dfValue_MamuA_1) + '-' + str(dfValue_MamuA_2)\n",
    "        pdDictKey_MamuB = str(dfValue_MamuB_1) + '-' + str(dfValue_MamuB_2)\n",
    "        pdDict_MamuA[pdDictKey_MamuA] = mamu_genotypes_oneHot\n",
    "        pdDict_MamuB[pdDictKey_MamuB] = mamu_genotypes_oneHot\n",
    "        alleleDF_MamuA = dataToPandasOneHot(pdDict_MamuA, alleleDF_MamuA, gListForIndex)\n",
    "        alleleDF_MamuB = dataToPandasOneHot(pdDict_MamuB, alleleDF_MamuB, gListForIndex)\n",
    "    return (alleleDF_MamuA, alleleDF_MamuB, gListForIndex)\n",
    "\n",
    "def createTupleOfOneHotAndLabels(npDataFrame, rowRange):\n",
    "    alleleDF_Mamu_parsedList = []\n",
    "    alleleDF_Mamu_listLabels_Y = []\n",
    "    rowRangeLimit = rowRange - 1\n",
    "    # Developer Comment: JRC\n",
    "    # I have no clue why, but this works, so I'm just going with it\n",
    "    skippedRowCount = 0\n",
    "    ct = 0\n",
    "    for i in range(0, rowRangeLimit):\n",
    "        # print('checking column ' + str(ct))\n",
    "        # print('length of alleleDF_Mamu_parsedList is ' + str(len(alleleDF_Mamu_parsedList)))\n",
    "        ct += 1\n",
    "        dfColAsSeries = npDataFrame.iloc[:,i]\n",
    "        if dfColAsSeries.name == 'nan-nan':\n",
    "            skippedRowCount += 1\n",
    "            continue\n",
    "        dfColAsList = dfColAsSeries.tolist()\n",
    "        alleleDF_Mamu_parsedList.append(dfColAsList)\n",
    "        alleleDF_Mamu_listLabels_Y.append(dfColAsSeries.name)\n",
    "    return (alleleDF_Mamu_parsedList, alleleDF_Mamu_listLabels_Y)\n",
    "\n",
    "def parseOutGenotypeNames(parsedIndicesList, gListParsed):\n",
    "    retList = []\n",
    "    for a in parsedMamuAIndices:\n",
    "        retList.append(gListParsed[a])\n",
    "    return retList\n",
    "\n",
    "def lambdaFunc(v):\n",
    "    return int(v)\n",
    "\n",
    "def openAndParse(f):\n",
    "    listValue = []\n",
    "    headerLine = ''\n",
    "    start = True\n",
    "    with open(f) as fOpen:\n",
    "        for i in fOpen:\n",
    "            if start:\n",
    "                iLine = i.split(',')\n",
    "                iLineDiscard = iLine.pop(0)\n",
    "                headerLine = ','.join(iLine)\n",
    "                start = False\n",
    "            else:\n",
    "                i = i.rstrip('\\n')\n",
    "                iSplit = i.split(',')\n",
    "                iSplitInt = list(map(lambdaFunc, iSplit[1:]))\n",
    "                # listValue.append((iSplit[0], iSplit[1:]))\n",
    "                listValue.append((iSplit[0], iSplitInt))\n",
    "    return (headerLine, listValue)\n",
    "\n",
    "def trainingDataToDataObject(tList):\n",
    "    # Developer Comment JRC:\n",
    "    # initial data structure is\n",
    "    # (genotypeList_string, [(haplotypeLabel_1, [row-one-hot-vector]),(haplotypeLabel_2, [row-one-hot-vector])])\n",
    "    trainingDataList_Mamu = []\n",
    "    colLabelsAsString = tList[0]\n",
    "    colLabelsAsList = colLabelsAsString.split(',')\n",
    "    tListValues = tList[1]\n",
    "    rowListOfVectors = []\n",
    "    genotypeList_trainingMamu = []\n",
    "    for i in tListValues:\n",
    "        rowListOfVectors.append(i[1])\n",
    "        genotypeList_trainingMamu.append(i[0])\n",
    "    for i in range(0, len(colLabelsAsList)):\n",
    "        lol_entry = [colLabelsAsList[i], genotypeList_trainingMamu, [], rowListOfVectors, [], [], []]\n",
    "        trainingDataList_Mamu.append(lol_entry)\n",
    "    return trainingDataList_Mamu\n",
    "\n",
    "\n",
    "def inputDataToDataObject(iListDF):\n",
    "    inputDataList_Mamu = []\n",
    "    listOfRowNames = []\n",
    "    listOfRowValues = []\n",
    "    listOfColumnNames = []\n",
    "    for rIdx,rItem in iListDF.iterrows():\n",
    "        listOfRowNames.append(str(rIdx))\n",
    "        rowValues = list(rItem)\n",
    "        listOfRowValues.append(rowValues)\n",
    "    ct = 0\n",
    "    for cItem in iListDF:\n",
    "        colName = str(cItem)\n",
    "        if colName == 'nan-nan':\n",
    "            print('removing ' + str(colName))\n",
    "            rmIdx = ct\n",
    "            for rItem in listOfRowValues:\n",
    "                del(rItem[rmIdx])\n",
    "            ct += 1\n",
    "            continue\n",
    "        listOfColumnNames.append(colName)\n",
    "        ct += 1\n",
    "    for i in range(0, len(listOfColumnNames)):\n",
    "        lol_entry = [listOfColumnNames[i], listOfRowNames, [], listOfRowValues, [], []]\n",
    "        inputDataList_Mamu.append(lol_entry)\n",
    "    return inputDataList_Mamu\n",
    "\n",
    "\n",
    "# Developer Comment JRC\n",
    "# The bug that kept skittering away was when doing a transform, pay careful attention to\n",
    "# which rows and columns are used, and the way the new data structure is formed. \n",
    "# When doing a columnToRow transform, you must create an empty list of lists-or array of arrays-\n",
    "# that has the same number of columns as the current dataset, then expand each list/array\n",
    "# When doing a rowToColumn transform, you must create a single list/array, then scan the rows \n",
    "# for the appropriately indexed value, and then proceed across the rows\n",
    "# As noted in other comments, in principle this will not change if the number of rows is expanded,\n",
    "# however, again, careful attention must be paid to the size and structure of the resulting list/array\n",
    "# since only specific lists/arrays in the newly expanded data object will have the correct count\n",
    "\n",
    "\n",
    "def sliceNames(l):\n",
    "    r = []\n",
    "    for i in l:\n",
    "        r.append(i[0])\n",
    "    return r\n",
    "\n",
    "def reorderTrainingAndInputDataLists(tDataList, iDataList):\n",
    "    vertList_tData = tDataList[0][3]\n",
    "    vertList_iData = iDataList[0][3]\n",
    "    tDataGenotypeListNames = tDataList[0][1] # sync using order from trainingList\n",
    "    iDataGenotypeListNames = iDataList[0][1]\n",
    "    # sanity check\n",
    "    if len(vertList_iData) != len(iDataGenotypeListNames):\n",
    "        print('WARNING! length mismatch in iData.  Check data objects before proceeding.')\n",
    "        print('length of ')\n",
    "        print(len(vertList_iData))\n",
    "        print(len(iDataGenotypeListNames))\n",
    "        return None\n",
    "    if len(vertList_tData) != len(tDataGenotypeListNames):\n",
    "        print('WARNING! length mismatch in tData.  Check data objects before proceeding.')\n",
    "        print(len(vertList_tData))\n",
    "        print(len(tDataGenotypeListNames))\n",
    "        return None\n",
    "    tData_iter = iter(vertList_tData)\n",
    "    iData_iter = iter(vertList_iData)\n",
    "    padValue = len(iDataList[0][3][0])\n",
    "    tDataTuple = list(zip(tDataGenotypeListNames, tData_iter))\n",
    "    iDataTuple = list(zip(iDataGenotypeListNames, iData_iter))\n",
    "    \n",
    "    # Dev Comment JRC:\n",
    "    # NOTE1: changing and padding the genotypes will not affect haplotype naming\n",
    "    # AS LONG AS both data structures are in the format of rows -> genotypes, columns -> haplotypes\n",
    "    # NOTE2: uncomment the lines below for debugging only\n",
    "    updatediDataList = []\n",
    "    for i in tDataGenotypeListNames:\n",
    "        try:\n",
    "            cIdx = iDataGenotypeListNames.index(i)\n",
    "            # print('appending ')\n",
    "            # print(iDataTuple[cIdx])\n",
    "            checkedValue = iDataTuple[cIdx]\n",
    "            updatediDataList.append(checkedValue)      \n",
    "        except ValueError:\n",
    "            # print(str(i) + ' not found!!')\n",
    "            # print('appending')\n",
    "            paddedList = [0]*padValue\n",
    "            paddediData = (i, paddedList)\n",
    "            # print(paddediData)\n",
    "            updatediDataList.append(paddediData)\n",
    "    updatediDataList_Genotypes, updatediDataList_onehotMultiList = zip(*updatediDataList)\n",
    "    return (updatediDataList_Genotypes, updatediDataList_onehotMultiList)\n",
    "\n",
    "\n",
    "def rows2Columns(l):\n",
    "    c = []\n",
    "    rowLen = len(l[0]) # assumes all rows have equal length\n",
    "    for j in range(0, rowLen):\n",
    "        singleRow = []\n",
    "        for i in l:\n",
    "            singleRow.append(i[j])\n",
    "        c.append(singleRow)\n",
    "    return c\n",
    "    \n",
    "def cols2Rows(l):\n",
    "    r = []\n",
    "    colLen = len(l[0])\n",
    "    for i in range(0, colLen):\n",
    "        singleColumn = []\n",
    "        for j in l:\n",
    "            singleColumn.append(j[i])\n",
    "        r.append(singleColumn)\n",
    "    return r\n",
    "\n",
    "def transposeRowsAndColumns(pandasDF):\n",
    "    rowNameList = []\n",
    "    colListNames = []\n",
    "    returnedDF = None\n",
    "    pdRowList = []\n",
    "    # create list of rownames, list of list of row values\n",
    "    for rIdx,rItem in pandasDF.iterrows():\n",
    "        rowNameList.append(str(rIdx))\n",
    "        rowValues = list(rItem)\n",
    "        pdRowList.append(rowValues)\n",
    "    \n",
    "    # Developer Comment JRC:\n",
    "    # create list of columnNames, using column.values() \n",
    "    # is an alternative but use with caution, because it had a tendency to break functionality without warning    \n",
    "    for cItem in pandasDF:\n",
    "        colName = str(cItem)\n",
    "        colListNames.append(colName)\n",
    "\n",
    "    # transpose rows_columns to a columns_rows list, then create a transposed dataframe\n",
    "    rowsColumns_xp_columnsRows = rows2Columns(pdRowList)\n",
    "    pandasDF_haplotypeX_genotypeY = pd.DataFrame(rowsColumns_xp_columnsRows, index=colListNames, columns=indexList)\n",
    "    return pandasDF_haplotypeX_genotypeY\n",
    "\n",
    "def transposeRowsAndColumnsFromDataObject(dObject):\n",
    "    # Dev Comment JRC: naming is in reference to the existing dObject, not the transformed object\n",
    "    rowNameList = []\n",
    "    colListNames = []\n",
    "    rowListofRows = []\n",
    "    rowNameList = dObject[0][1]\n",
    "    rowListOfRows = dObject[0][3]\n",
    "    transposed_rowsToColumns = rows2Columns(rowListOfRows)\n",
    "    for i in range(0, len(dObject)):\n",
    "        dObject[i][2] = transposed_rowsToColumns[i]\n",
    "    return dObject\n",
    "\n",
    "\n",
    "def parsedColumnData(l, idx):\n",
    "    resList = []\n",
    "    for itm in l:\n",
    "        resList.append(itm[2][idx])\n",
    "    return resList\n",
    "def parseForML(l):\n",
    "    labels_Y = []\n",
    "    values_X = []\n",
    "    for i in l:\n",
    "        labels_Y.append(i[0])\n",
    "        # tmp = parsedColumnData(l, ct)\n",
    "        values_X.append(i[2])\n",
    "    return (labels_Y, values_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGiven a table structure of values, where a horizontal axis is defined as x and a vertical axis is defined as y:\\n           Haplotype_1 | Haplotype_2 | Haplotype_3\\ngenotype_1     0            0             1\\ngenotype_2     0            1             0\\ngenotype_3     1            1             0\\n\\nlen(x) may equal len(y), but it is not required\\nall x are equal length, and all y are equal length\\n\\nlet g = len(y)\\nlet h = len(x)\\n\\na row-structured version of the data is defined as\\nA = [[genotype_1:[y_1_1, y_2_1,...,y_n_1]],[genotype_1:[y_1_2, y_2_2,...,y_n_2]]]\\nwhile a column-structured version of the data is defined as\\nB = [[Haplotype_1:[x_1_1, x_2_1,...,x_n_1],[Haplotype_2:[x_1_2, x_2_2,...,x_n_2]]]\\n\\ntransposing or transforming the values from row-structured to column-structured can be defined as:\\n\\ntransposing the X to the Y axis, defined as X_transposed == {X(row) and Y(column) values interchanged} and \\ntransposing the Y to the X axis, defined as Y_transposed == {Y(column) and X(row) values interchanged} can be described with:\\n\\nlen(X_transposed_column) == len(g)\\nlen(Y_transposed_column) == len(h)\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Developer Comment JRC:\n",
    "'''\n",
    "Given a table structure of values, where a horizontal axis is defined as x and a vertical axis is defined as y:\n",
    "           Haplotype_1 | Haplotype_2 | Haplotype_3\n",
    "genotype_1     0            0             1\n",
    "genotype_2     0            1             0\n",
    "genotype_3     1            1             0\n",
    "\n",
    "len(x) may equal len(y), but it is not required\n",
    "all x are equal length, and all y are equal length\n",
    "\n",
    "let g = len(y)\n",
    "let h = len(x)\n",
    "\n",
    "a row-structured version of the data is defined as\n",
    "A = [[genotype_1:[y_1_1, y_2_1,...,y_n_1]],[genotype_1:[y_1_2, y_2_2,...,y_n_2]]]\n",
    "while a column-structured version of the data is defined as\n",
    "B = [[Haplotype_1:[x_1_1, x_2_1,...,x_n_1],[Haplotype_2:[x_1_2, x_2_2,...,x_n_2]]]\n",
    "\n",
    "transposing or transforming the values from row-structured to column-structured can be defined as:\n",
    "\n",
    "transposing the X to the Y axis, defined as X_transposed == {X(row) and Y(column) values interchanged} and \n",
    "transposing the Y to the X axis, defined as Y_transposed == {Y(column) and X(row) values interchanged} can be described with:\n",
    "\n",
    "len(X_transposed_column) == len(g)\n",
    "len(Y_transposed_column) == len(h)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing nan-nan\n",
      "removing nan-nan\n"
     ]
    }
   ],
   "source": [
    "#PRAGMA Mark: formatDataStructure\n",
    "# format data for data structure, match data in input and training,\n",
    "# then transpose to genotypes in the columns (gY) and haplotypes in the rows (hX)\n",
    "v = findColumnIdxStartStop(excelSheetName)\n",
    "if v[0] == -1:\n",
    "    print('Error!  check dataframe!')\n",
    "col1List = list(excelSheetName['Sample Sheet #']) # this needs to be updated\n",
    "skipRows, mamuA_rows, mamuB_rows, genotypeList_unparsed = parsePandasDfRows(col1List)\n",
    "genotypeList_parsed = []\n",
    "genotypeList_parsed = parseGenotypeList(genotypeList_unparsed)\n",
    "\n",
    "if genotypeList_parsed is None:\n",
    "    genotypeList_parsed = genotypeList_unparsed\n",
    "\n",
    "\n",
    "skipMamuRows = mamuA_rows + mamuB_rows + skipRows\n",
    "skipMamuRows.sort()\n",
    "parsedMamuIndices = parseIdxForMamuAMamuB(genotypeList_parsed)\n",
    "parsedMamuAIndices = parsedMamuIndices[0] # indices matching \"Mamu-A\"\n",
    "parsedMamuBIndices = parsedMamuIndices[1] # indices matching \"Mamu-B\"\n",
    "\n",
    "rStart = v[0]\n",
    "rStop = v[1] + 1\n",
    "rRange = rStop - rStart\n",
    "allele_DF_result = parseDataIntoPandasDF(rStart, rStop, mamuA_rows, mamuB_rows, skipMamuRows, excelSheetName, genotypeList_parsed)\n",
    "\n",
    "alleleDF_MamuA_result = allele_DF_result[0]\n",
    "alleleDF_MamuB_result = allele_DF_result[1]\n",
    "alleleDF_MamuA_parsed = alleleDF_MamuA_result.iloc[parsedMamuAIndices,:]\n",
    "alleleDF_MamuB_parsed = alleleDF_MamuB_result.iloc[parsedMamuBIndices,:]\n",
    "\n",
    "alleleDF_MamuA_parsed_asDataObject = inputDataToDataObject(alleleDF_MamuA_parsed)\n",
    "alleleDF_MamuB_parsed_asDataObject = inputDataToDataObject(alleleDF_MamuB_parsed)\n",
    "\n",
    "\n",
    "# training data, testing here only tests the accuracy and is only for mhcA\n",
    "trainingValues_mhcA = openAndParse('allele_df-trainingSet-HapA_transposed.csv')\n",
    "testingValues_mhcA = openAndParse('allele_df-testingSet-HapA_transposed.csv')\n",
    "trainingValues_mhcB = openAndParse('allele_df-trainingSet-HapB_transposed.csv')\n",
    "\n",
    "trainingDataList_MamuA = trainingDataToDataObject(trainingValues_mhcA)\n",
    "testingDataList_MamuA = trainingDataToDataObject(testingValues_mhcA)\n",
    "trainingDataList_MamuB = trainingDataToDataObject(trainingValues_mhcB)\n",
    "\n",
    "\n",
    "matched_inputDataListTuple_mhcA = reorderTrainingAndInputDataLists(trainingDataList_MamuA, alleleDF_MamuA_parsed_asDataObject)\n",
    "matched_testingDataListTuple_mhcA = reorderTrainingAndInputDataLists(trainingDataList_MamuA, testingDataList_MamuA)\n",
    "matched_inputDataListTuple_mhcB = reorderTrainingAndInputDataLists(trainingDataList_MamuB, alleleDF_MamuB_parsed_asDataObject)\n",
    "\n",
    "\n",
    "updatedMatchedGenotypeList_testing = list(matched_testingDataListTuple_mhcA[0])\n",
    "updatedMatchedOneHotVectorList_testing = list(matched_testingDataListTuple_mhcA[1])\n",
    "\n",
    "\n",
    "\n",
    "for i in testingDataList_MamuA:\n",
    "    i[1] = updatedMatchedGenotypeList_testing\n",
    "    i[3] = updatedMatchedOneHotVectorList_testing\n",
    "\n",
    "updatedMatchedGenotypeList = list(matched_inputDataListTuple_mhcA[0])\n",
    "updatedMatchedOneHotVectorList = list(matched_inputDataListTuple_mhcA[1])\n",
    "for i in alleleDF_MamuA_parsed_asDataObject:\n",
    "    i[1] = updatedMatchedGenotypeList\n",
    "    i[3] = updatedMatchedOneHotVectorList\n",
    "\n",
    "updatedMatchedGenotypeList_mhcB = list(matched_inputDataListTuple_mhcB[0])\n",
    "updatedMatchedOneHotVectorList_mhcB = list(matched_inputDataListTuple_mhcB[1])\n",
    "for i in alleleDF_MamuB_parsed_asDataObject:\n",
    "    i[1] = updatedMatchedGenotypeList_mhcB\n",
    "    i[3] = updatedMatchedOneHotVectorList_mhcB\n",
    "\n",
    "alleleDF_MamuA_hX_gY = transposeRowsAndColumnsFromDataObject(alleleDF_MamuA_parsed_asDataObject)\n",
    "alleleDF_MamuA_hX_gY_training = transposeRowsAndColumnsFromDataObject(trainingDataList_MamuA)\n",
    "alleleDF_MamuA_hX_gY_testing = transposeRowsAndColumnsFromDataObject(testingDataList_MamuA)\n",
    "alleleDF_MamuB_hX_gY = transposeRowsAndColumnsFromDataObject(alleleDF_MamuB_parsed_asDataObject)\n",
    "alleleDF_MamuB_hX_gY_training = transposeRowsAndColumnsFromDataObject(trainingDataList_MamuB)\n",
    "\n",
    "trainingDataList_MamuB\n",
    "# patch to remove newlines that slipped in, write a better one later\n",
    "for i in alleleDF_MamuA_hX_gY_testing:\n",
    "    iStrip = i[0].replace('\\n', '')\n",
    "    i[0] = iStrip\n",
    "for i in alleleDF_MamuA_hX_gY_training:\n",
    "    iStrip = i[0].replace('\\n', '')\n",
    "    i[0] = iStrip\n",
    "# alleleDF_MamuB_hX_gY = transposeRowsAndColumns(alleleDF_MamuB_parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Developer Comment JRC\n",
    "'''\n",
    "There is a fork in the workflow here.  Currently, the data is added to a pandas dataframe,\n",
    "then the pandas dataframe is filtered for only MHC-A and MHC-B values using a pre-created index. \n",
    "Next, this filtered dataframe is used to create a transposed dataframe of rows and columns. \n",
    "An alternative option is one could create an unfiltered dataframe and transpose that, using the unparsed\n",
    "genotypeList to verify the correct rows are selected, but all filtering *must* \n",
    " - be completed before transposing row and column values\n",
    " - ONLY be done when genotypes are the row values\n",
    "or the entire organization of the data structure will collapse.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valuesToIntList(valList):\n",
    "    listedValues = []\n",
    "    ct = 0\n",
    "    l_strings = []\n",
    "    l_ints = []\n",
    "    l_strings_r = []\n",
    "    l_ints_r = []\n",
    "    npArrayList = []\n",
    "    for i in valList:\n",
    "        if i not in l_strings:\n",
    "            l_strings_r.append(i)\n",
    "            l_ints_r.append(ct)\n",
    "            l_strings.append(i)\n",
    "            l_ints.append(ct)\n",
    "            npArrayList.append(ct)\n",
    "            ct += 1\n",
    "        else:\n",
    "            v_i = l_strings.index(i)\n",
    "            v_i_string = l_strings[v_i]\n",
    "            v_ct = l_ints[v_i]\n",
    "            l_strings_r.append(v_i_string)\n",
    "            l_ints_r.append(v_ct)\n",
    "            npArrayList.append(v_ct)\n",
    "    npArrayTupleList = list(zip(l_strings_r,l_ints_r))\n",
    "    return (npArrayList, npArrayTupleList)\n",
    "\n",
    "def scanLabelTuple(s, t):\n",
    "    for i in t:\n",
    "        if i[0] == s:\n",
    "            return (s, i[1])\n",
    "    return (False, -1)\n",
    "def updateLabelInts(valList, tupleList):\n",
    "    listedValues = []\n",
    "    ct = 0\n",
    "    l_strings = []\n",
    "    l_ints = []\n",
    "    l_strings_r = []\n",
    "    l_ints_r = []\n",
    "    npArrayList = []\n",
    "    for i in valList:\n",
    "        if i not in l_strings:\n",
    "            scannedResult = scanLabelTuple(i, tupleList)\n",
    "            if scannedResult[0] != False:\n",
    "                l_strings.append(scannedResult[0])\n",
    "                l_ints.append(scannedResult[1])\n",
    "                l_strings_r.append(scannedResult[0])\n",
    "                l_ints_r.append(scannedResult[1])\n",
    "                npArrayList.append(scannedResult[1])\n",
    "            else:\n",
    "                print('WARNING!  Value ' + str(i) + ' not found in training Data,\\nwhich will cause a dramatic decrease in accuracy,\\nbut this will be addressed in the next version')\n",
    "                l_strings.append(scannedResult[0])\n",
    "                l_ints.append(scannedResult[1])\n",
    "                l_strings_r.append(scannedResult[0])\n",
    "                l_ints_r.append(scannedResult[1])\n",
    "                npArrayList.append(scannedResult[1])\n",
    "        else:\n",
    "            v_i = l_strings.index(i)\n",
    "            v_i_string = l_strings[v_i]\n",
    "            v_ct = l_ints[v_i]\n",
    "            l_strings_r.append(v_i_string)\n",
    "            l_ints_r.append(v_ct)\n",
    "            npArrayList.append(v_ct)\n",
    "    npArrayTupleList = list(zip(l_strings_r,l_ints_r))\n",
    "    return (npArrayList, npArrayTupleList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHC-A\n",
    "training_set = parseForML(alleleDF_MamuA_hX_gY_training)\n",
    "X_trainList = training_set[1]\n",
    "Y_trainList = training_set[0]\n",
    "\n",
    "# Developer Comment JRC: \n",
    "# uncomment the next two lines to use a premade testing dataset for debugging\n",
    "# testing_set = parseForML(alleleDF_MamuA_hX_gY_testing)\n",
    "# X_testList = testing_set[1]\n",
    "# Y_testList = testing_set[0]\n",
    "\n",
    "testing_set = parseForML(alleleDF_MamuA_hX_gY)\n",
    "X_testList = testing_set[1]\n",
    "Y_testListUnparsed = testing_set[0]\n",
    "Y_testList = parseLabeledValues(Y_testListUnparsed)\n",
    "\n",
    "X_train = np.array(X_trainList)\n",
    "X_test = np.array(X_testList)\n",
    "Y_trainTuple = valuesToIntList(Y_trainList)\n",
    "Y_train = Y_trainTuple[0]\n",
    "\n",
    "Y_testTuple = updateLabelInts(Y_testList, Y_trainTuple[1])\n",
    "Y_test = Y_testTuple[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is \n",
      "0.959459459459\n",
      "The Classifier predicted A023 but the actual value was A016-A023\n",
      "The Classifier predicted A004 but the actual value was A004-A025\n",
      "The Classifier predicted A025 but the actual value was A011-A025\n",
      "\n",
      "\n",
      "The output has been written to the file resultsMHC_A_Output.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "forest_clf_pred = forest_clf.predict(X_test)\n",
    "\n",
    "# Developer Comment JRC:\n",
    "# uncomment the next two lines for a raw output\n",
    "# print(forest_clf_pred)\n",
    "# print(Y_test)\n",
    "print('Accuracy Score is ')\n",
    "print(accuracy_score(Y_test, forest_clf_pred))\n",
    "\n",
    "def resultsLookup(rInt, tList):\n",
    "    for t in tList:\n",
    "        if t[1] == rInt:\n",
    "            return t[0]\n",
    "    return None\n",
    "    \n",
    "resultsList = []\n",
    "for x in range(0, len(Y_test)):\n",
    "    testValue = Y_test[x]\n",
    "    predictedValue = forest_clf_pred[x]\n",
    "    lookupString = resultsLookup(testValue, Y_trainTuple[1])\n",
    "    lookupString_predicted = resultsLookup(predictedValue, Y_trainTuple[1])\n",
    "    if testValue != predictedValue:\n",
    "        print('The Classifier predicted ' + str(lookupString_predicted) + ' but the actual value was ' + str(lookupString))\n",
    "        resultsList.append((lookupString_predicted, lookupString))\n",
    "    else:\n",
    "        resultsList.append((lookupString_predicted, lookupString))\n",
    "\n",
    "\n",
    "s_out_predicted = ''\n",
    "s_out_actual = ''\n",
    "for x in resultsList:\n",
    "    s_out_predicted += str(x[0]) + ','\n",
    "    s_out_actual += str(x[1]) + ','\n",
    "s_out_predicted = s_out_predicted[:-1]\n",
    "s_out_actual = s_out_actual[:-1]\n",
    "with open('resultsMHC_A_Output.txt', 'w') as fWrite:\n",
    "    # print(\"Purchase Amount: {}\".format(TotalAmount), file=text_file)\n",
    "    print('Table of Predicted (row 1) vs. Actual values (row 2)', file=fWrite)\n",
    "    # print('\\n', file=fWrite)\n",
    "    print(s_out_predicted, file=fWrite)\n",
    "    # print('\\n', file=fWrite)\n",
    "    print(s_out_actual, file=fWrite)\n",
    "    print('\\n', file=fWrite)\n",
    "    print('Accuracy Score is: ' + str(accuracy_score(Y_test, forest_clf_pred)),file=fWrite)\n",
    "    \n",
    "print('\\n\\nThe output has been written to the file resultsMHC_A_Output.txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!  Value B012b-B093' not found in training Data,\n",
      "which will cause a dramatic decrease in accuracy,\n",
      "but this will be addressed in the next version\n",
      "WARNING!  Value B024a-B106' not found in training Data,\n",
      "which will cause a dramatic decrease in accuracy,\n",
      "but this will be addressed in the next version\n"
     ]
    }
   ],
   "source": [
    "# MHC-B\n",
    "training_set = parseForML(alleleDF_MamuB_hX_gY_training)\n",
    "X_trainList = training_set[1]\n",
    "Y_trainList = training_set[0]\n",
    "\n",
    "testing_set = parseForML(alleleDF_MamuB_hX_gY)\n",
    "X_testList = testing_set[1]\n",
    "Y_testListUnparsed = testing_set[0]\n",
    "Y_testList = parseLabeledValues(Y_testListUnparsed)\n",
    "\n",
    "X_train = np.array(X_trainList)\n",
    "X_test = np.array(X_testList)\n",
    "Y_trainTuple = valuesToIntList(Y_trainList)\n",
    "Y_train = Y_trainTuple[0]\n",
    "\n",
    "Y_testTuple = updateLabelInts(Y_testList, Y_trainTuple[1])\n",
    "Y_test = Y_testTuple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is \n",
      "0.932432432432\n",
      "The Classifier predicted B012b-B093 but the actual value was None\n",
      "The Classifier predicted B015a-B012b but the actual value was B012b-B015a\n",
      "The Classifier predicted B015a-B012b but the actual value was B012b-B015a\n",
      "The Classifier predicted B015a-B012b but the actual value was B012b-B015a\n",
      "The Classifier predicted B024a-B106 but the actual value was None\n",
      "\n",
      "\n",
      "The output has been written to the file resultsMHC_B_Output.txt\n"
     ]
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "forest_clf_pred = forest_clf.predict(X_test)\n",
    "\n",
    "# Developer Comment JRC:\n",
    "# uncomment the next two lines for a raw output\n",
    "# print(forest_clf_pred)\n",
    "# print(Y_test)\n",
    "print('Accuracy Score is ')\n",
    "print(accuracy_score(Y_test, forest_clf_pred))\n",
    "\n",
    "def resultsLookup(rInt, tList):\n",
    "    for t in tList:\n",
    "        if t[1] == rInt:\n",
    "            return t[0]\n",
    "    return None\n",
    "    \n",
    "resultsList = []\n",
    "for x in range(0, len(Y_test)):\n",
    "    testValue = Y_test[x]\n",
    "    predictedValue = forest_clf_pred[x]\n",
    "    lookupString = resultsLookup(testValue, Y_trainTuple[1])\n",
    "    lookupString_predicted = resultsLookup(predictedValue, Y_trainTuple[1])\n",
    "    if testValue != predictedValue:\n",
    "        print('The Classifier predicted ' + str(lookupString_predicted) + ' but the actual value was ' + str(lookupString))\n",
    "        resultsList.append((lookupString_predicted, lookupString))\n",
    "    else:\n",
    "        resultsList.append((lookupString_predicted, lookupString))\n",
    "\n",
    "\n",
    "s_out_predicted = ''\n",
    "s_out_actual = ''\n",
    "for x in resultsList:\n",
    "    s_out_predicted += str(x[0]) + ','\n",
    "    s_out_actual += str(x[1]) + ','\n",
    "s_out_predicted = s_out_predicted[:-1]\n",
    "s_out_actual = s_out_actual[:-1]\n",
    "with open('resultsMHC_B_Output.txt', 'w') as fWrite:\n",
    "    # print(\"Purchase Amount: {}\".format(TotalAmount), file=text_file)\n",
    "    print('Table of Predicted (row 1) vs. Actual values (row 2)', file=fWrite)\n",
    "    # print('\\n', file=fWrite)\n",
    "    print(s_out_predicted, file=fWrite)\n",
    "    # print('\\n', file=fWrite)\n",
    "    print(s_out_actual, file=fWrite)\n",
    "    print('\\n', file=fWrite)\n",
    "    print('Accuracy Score is: ' + str(accuracy_score(Y_test, forest_clf_pred)),file=fWrite)\n",
    "    \n",
    "print('\\n\\nThe output has been written to the file resultsMHC_B_Output.txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
