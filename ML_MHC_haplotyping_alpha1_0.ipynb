{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comments from John\n",
    "\n",
    "# This workflow is very much in an alpha state\n",
    "# The current code is provided primarily as a reference\n",
    "# A beta build (see below) will be provided ASAP for testing and general use\n",
    "\n",
    "# # alpha -> software works but may have bugs and is under development\n",
    "# # beta -> most bugs have been fixed, software is ready for wider testing\n",
    "# # release -> all problems have been fixed and software is ready for widespread distribution\n",
    "\n",
    "# The end goal is to create a python notebook that wil run the Machine Learning classifier defined here\n",
    "# but will not require knowledge of Machine Learning by the researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def lambdaFunc(v):\n",
    "    return int(v)\n",
    "\n",
    "def openAndParse(f):\n",
    "    listValue = []\n",
    "    headerLine = ''\n",
    "    start = True\n",
    "    with open(f) as fOpen:\n",
    "        for i in fOpen:\n",
    "            if start:\n",
    "                iLine = i.split(',')\n",
    "                iLine = iLine.pop(0)\n",
    "                headerLine = ','.join(iLine)\n",
    "                start = False\n",
    "            else:\n",
    "                i = i.rstrip('\\n')\n",
    "                iSplit = i.split(',')\n",
    "                iSplitInt = list(map(lambdaFunc, iSplit[1:]))\n",
    "                # listValue.append((iSplit[0], iSplit[1:]))\n",
    "                listValue.append((iSplit[0], iSplitInt))\n",
    "    return (headerLine, listValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert dataset csv filenames.  They MUST be formatted as defined by Experiment 21324\n",
    "# Future builds will take care of formatting, and will accept pivot tables and MiSeq output\n",
    "\n",
    "trainingValues = openAndParse('allele_df-trainingSet-HapA.csv')\n",
    "testingValues = openAndParse('allele_df-testingSet-HapA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[                  0 8101242554838556677                   0 ...,\n",
      "  7308339944545415026 2915076257986120233 8391162080290301292]\n",
      " [7310868735423114857 7813874358961533510 7741528794290792805 ...,\n",
      "  8656044306584971621 7453001576143022368 8031170617525938277]\n",
      " [4190992423152865904 7013900260281950218 2323048684161693036 ...,\n",
      "           4294967297                   0         42949672962]\n",
      " ..., \n",
      " [    140600934913568                   1         64424509458 ...,\n",
      "      140600934914200          8589934620          4436819784]\n",
      " [                  1         12884927744         17179869204 ...,\n",
      "                 6400         17179869207                   0]\n",
      " [              25600                   0                   0 ...,\n",
      "                    0                   0                   0]]\n",
      "(21, 61)\n",
      "\n",
      "\n",
      "\n",
      "[ 1152921504606846976 -5764598735475447064                   15\n",
      "                    0           4294967296  7235419174270214779\n",
      "  4771073664489765410  3762815969819509301  3473174958971236407\n",
      "  4991169499966293571  8319593459584874309  4189022123868451429\n",
      "  7881702260482471202  8319104481852400229  5063209514152390505\n",
      "  3979004183733023302  4123098519742726961  4770495321374800182\n",
      "  3180180442070725700  8104636957536251170  7162263158163907173]\n",
      "(21,)\n",
      "[('A001-A002a', [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('A001', [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('A001-A002a', [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A001-A004', [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A001-A004', [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]), ('A001-A002a', [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]), ('A004-A008', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004-A023', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]), ('A004-A023', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A001-A008', [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('A004-A008', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004-A008', [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]), ('A002a-A006', [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A002a-A004', [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A002a-A004', [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]), ('A004', [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "X_train = np.empty([len(trainingValues[1]), len(trainingValues[1][1][1])], dtype=int)\n",
    "Y_train = np.empty([len(trainingValues[1])], dtype=int)\n",
    "X_test = np.empty([len(testingValues[1]), len(testingValues[1][1][1])], dtype=int)\n",
    "Y_test = np.empty([len(testingValues[1])], dtype=int)\n",
    "print(X_test)\n",
    "print(X_test.shape)\n",
    "print('\\n\\n')\n",
    "print(Y_test)\n",
    "print(Y_test.shape)\n",
    "trainingValueFromTuple = trainingValues[1]\n",
    "testingValueFromTuple = testingValues[1]\n",
    "print(testingValueFromTuple)\n",
    "print(len(testingValueFromTuple))\n",
    "lookupTableBecauseNumpy = []\n",
    "lookupTableBecauseNumpyTesting = []\n",
    "stopRange = len(trainingValueFromTuple)\n",
    "for x in range(0, stopRange):\n",
    "    aValue_x = trainingValueFromTuple[x][1]\n",
    "    aValue_y = trainingValueFromTuple[x][0]\n",
    "    X_train[x] = aValue_x\n",
    "    # X_train[x] = aValue_xList\n",
    "    # np.insert(X_train[x], aValue_xList)\n",
    "    lookupTableBecauseNumpy.append(aValue_y)\n",
    "    Y_train[x] = np.array(x, dtype=int)\n",
    "stopRange = len(testingValueFromTuple)\n",
    "for x in range(0, stopRange):\n",
    "    aValue_x = testingValueFromTuple[x][1]\n",
    "    aValue_y = testingValueFromTuple[x][0]\n",
    "    X_test[x] = aValue_x\n",
    "    lookupTableBecauseNumpyTesting.append(aValue_y)\n",
    "    Y_test[x] = np.array(x, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  1  2  2  3  4  5  4  6  1  0  2  4  7  8  8  9  3  7  7  0  0\n",
      "  0  4 10  0 10  0 11  0  8  5  5  3  6  7  5  7 11  7  0  4  4  9  2  0 10\n",
      "  7  7  0  2  9  0  9  2  0  4  0 10  4  0  0  9  2  7  0  5  5  1  0  9  7\n",
      "  3  0  0  0  0  7  5  9  0  9  2  0]\n",
      "[('A004', 0), ('A004', 0), ('A004', 0), ('A004', 0), ('A004-A025', 1), ('A002a-A004', 2), ('A002a-A004', 2), ('A004-A011', 3), ('A004-A023', 4), ('A001-A008', 5), ('A004-A023', 4), ('A002a-A006', 6), ('A004-A025', 1), ('A004', 0), ('A002a-A004', 2), ('A004-A023', 4), ('A004-A008', 7), ('A001', 8), ('A001', 8), ('A001-A004', 9), ('A004-A011', 3), ('A004-A008', 7), ('A004-A008', 7), ('A004', 0), ('A004', 0), ('A004', 0), ('A004-A023', 4), ('A001-A002a', 10), ('A004', 0), ('A001-A002a', 10), ('A004', 0), ('A002a-A008', 11), ('A004', 0), ('A001', 8), ('A001-A008', 5), ('A001-A008', 5), ('A004-A011', 3), ('A002a-A006', 6), ('A004-A008', 7), ('A001-A008', 5), ('A004-A008', 7), ('A002a-A008', 11), ('A004-A008', 7), ('A004', 0), ('A004-A023', 4), ('A004-A023', 4), ('A001-A004', 9), ('A002a-A004', 2), ('A004', 0), ('A001-A002a', 10), ('A004-A008', 7), ('A004-A008', 7), ('A004', 0), ('A002a-A004', 2), ('A001-A004', 9), ('A004', 0), ('A001-A004', 9), ('A002a-A004', 2), ('A004', 0), ('A004-A023', 4), ('A004', 0), ('A001-A002a', 10), ('A004-A023', 4), ('A004', 0), ('A004', 0), ('A001-A004', 9), ('A002a-A004', 2), ('A004-A008', 7), ('A004', 0), ('A001-A008', 5), ('A001-A008', 5), ('A004-A025', 1), ('A004', 0), ('A001-A004', 9), ('A004-A008', 7), ('A004-A011', 3), ('A004', 0), ('A004', 0), ('A004', 0), ('A004', 0), ('A004-A008', 7), ('A001-A008', 5), ('A001-A004', 9), ('A004', 0), ('A001-A004', 9), ('A002a-A004', 2), ('A004', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Commentary from John:\n",
    "'''\n",
    "One thing I kept scratching my head over--and then subsequently face-palming over--was why\n",
    "the linear model for the Classifier simply refused to work.\n",
    "\n",
    "As a cautionary tale to anyone else, what was happening was I had correctly set up the X values as a one-hot vector, \n",
    "but then when I set the labels for Y, I assigned each one to a unique integer and then mapped them back to the corresponding string values.\n",
    "This meant the linear model was being set up as \n",
    "X          Y \n",
    "[vector]   0\n",
    "[vector]   1\n",
    "[vector]   2\n",
    "[vector]   3\n",
    "\n",
    "Where each vector was something like:\n",
    "[0,0,0,1,0,0]\n",
    "\n",
    "And each Y integer was unique, and mapped back to a string, like \"A001\".  \n",
    " \n",
    "The vectors were created from the allele names, where a mapping table was created that defined an allele that was present or not for a given haplotype (order was maintained).\n",
    "Each vector represents an instance in an experiment where alleles for a sample mapped back to a haplotype as allele frequencies.  \n",
    "Initially, replicated instances of Haplotypes were flattened and merged, however, I'll leave it as an exercise to the reader to see just how poorly this implementaion fit any linear model. \n",
    "\n",
    "What I should have been doing (and subsequently did) was:\n",
    "X          Y \n",
    "[vector]   0\n",
    "[vector]   0\n",
    "[vector]   0\n",
    "[vector]   1\n",
    "[vector]   1\n",
    "\n",
    "Where again, each vector was something like:\n",
    "[0,0,0,1,0,0]\n",
    "\n",
    "Each Y integer was each instance of the corresponding haplotype, like \"A001\", that mapped to it\n",
    "Subsequently, all allele frequencies were included, regardless if the same allele pairing was repeated.\n",
    "This created a usable linear model, and multiple n values that the library could use for calculations.\n",
    "\n",
    "\n",
    "'''\n",
    "# For these purposes, the labels were manually reformatted (see above) by visually scanning the list .  This will be automated.\n",
    "\n",
    "def formatTestingValues(tList, tupleList):\n",
    "    r = []\n",
    "    validationInt = len(tList)\n",
    "    for v in tList:\n",
    "        for vInTuple in tupleList:\n",
    "            if v == vInTuple[0]:\n",
    "                r.append(vInTuple[1])\n",
    "                break\n",
    "    if len(r) != len(tList):\n",
    "        print('WARNING!')\n",
    "        print(r)\n",
    "        print(tList)\n",
    "        return None\n",
    "    else:\n",
    "        return r\n",
    "def valuesToTestList(valList, npArrayTupleList):\n",
    "    r = []\n",
    "    matched = False\n",
    "    for v in valList:\n",
    "        for vTuple in npArrayTupleList:\n",
    "            if v == vTuple[0]:\n",
    "                matched = True\n",
    "                r.append(vTuple[1])\n",
    "                break\n",
    "        if matched:\n",
    "            matched = False\n",
    "            continue\n",
    "        else:\n",
    "            print('WARNING!')\n",
    "            print(valList)\n",
    "            print(npArrayTupleList)\n",
    "            return None\n",
    "    return r\n",
    "        \n",
    "    \n",
    "def valuesToIntList(valList):\n",
    "    listedValues = []\n",
    "    ct = 0\n",
    "    l_strings = []\n",
    "    l_ints = []\n",
    "    l_strings_r = []\n",
    "    l_ints_r = []\n",
    "    npArrayList = []\n",
    "    for i in valList:\n",
    "        if i not in l_strings:\n",
    "            l_strings_r.append(i)\n",
    "            l_ints_r.append(ct)\n",
    "            l_strings.append(i)\n",
    "            l_ints.append(ct)\n",
    "            npArrayList.append(ct)\n",
    "            ct += 1\n",
    "        else:\n",
    "            v_i = l_strings.index(i)\n",
    "            v_i_string = l_strings[v_i]\n",
    "            v_ct = l_ints[v_i]\n",
    "            l_strings_r.append(v_i_string)\n",
    "            l_ints_r.append(v_ct)\n",
    "            npArrayList.append(v_ct)\n",
    "    npArrayTupleList = list(zip(l_strings_r,l_ints_r))\n",
    "    return (npArrayList, npArrayTupleList)\n",
    "'''\n",
    "listedValues = []\n",
    "ct = 0\n",
    "l_strings = []\n",
    "l_ints = []\n",
    "l_strings_r = []\n",
    "l_ints_r = []\n",
    "print('[')\n",
    "npArrayList = []\n",
    "for i in lookupTableBecauseNumpy:\n",
    "    if i not in l_strings:\n",
    "        print(str(i) + ',' + str(ct))\n",
    "        l_strings_r.append(i)\n",
    "        l_ints_r.append(ct)\n",
    "        # print(str(ct) + ',')\n",
    "        l_strings.append(i)\n",
    "        l_ints.append(ct)\n",
    "        npArrayList.append(ct)\n",
    "        ct += 1\n",
    "    else:\n",
    "        v_i = l_strings.index(i)\n",
    "        v_i_string = l_strings[v_i]\n",
    "        v_ct = l_ints[v_i]\n",
    "        print(str(v_i_string) + ',' + str(v_ct))\n",
    "        l_strings_r.append(v_i_string)\n",
    "        l_ints_r.append(v_ct)\n",
    "        npArrayList.append(v_ct)\n",
    "        # print(str(v_ct) + ',')\n",
    "# print(']')\n",
    "# print(npArrayList)\n",
    "'''\n",
    "\n",
    "parsedTrainingResults = valuesToIntList(lookupTableBecauseNumpy)\n",
    "Y_train = np.array(parsedTrainingResults[0])\n",
    "parsedTestingResults = valuesToIntList(lookupTableBecauseNumpyTesting)\n",
    "Y_testList = valuesToTestList(lookupTableBecauseNumpyTesting, parsedTestingResults[1])\n",
    "print(Y_train)\n",
    "print(parsedTrainingResults[1])\n",
    "Y_test = np.array(Y_testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list lengths are equal, proceeding...\n",
      "All values match!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(X_test.shape)\\nprint(X_train.shape)\\nprint(Y_train.shape)\\nprint(Y_test.shape)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "x = [0,1,2,3,4,4,5,6,7,7,8,9,8,10,11,12,13,14,14,15,15,16,17,17,18,11,2,11,0,0,19,19,20,20,21,22,0,0,18,2,22,3,23,23,9,24,24,2,7,25,26,27,22,28,28,18,11,11,11,11,7,9,5,29,29,10,30,31,10,11,27,7,11,11,9,16,10,10,13,32,10,7,27,10,10,33,7,7,9,34,10,32,21,10,1,11,35,35,18,22,7,16,16,16,30,36,36,36,37,37,11,31,38,38,2,11,7,31,39,9,40,40,31,13,7,7,33,41,41,11,42,42,18,11,43,8,44,44,6,21,11,11,0,8,2,11,8,8,8,45,11,8,11,11,2,43,43,11,39,39,46,46,0,22,11,11,22,39,47,47,22,45,48,49,49,26,11,22,0,11,22,50,50,11,22,11,42,48,39,11,22,11,11,26,31,51,51,16,7,9,12,52,52,27,53,53,54,54,55,55,16,2,22,56,11,11,34,11,32,9,57,57,58,58,25,22,0,56,59,59,9,1,45,60,60,11,22,2,9,61,61,11,11,62,62,11,26]\n",
    "y = [0, 1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 8, 10, 11, 12, 13, 14, 14, 15, 15, 16, 17, 17, 18, 11, 2, 11, 0, 0, 19, 19, 20, 20, 21, 22, 0, 0, 18, 2, 22, 3, 23, 23, 9, 24, 24, 2, 7, 25, 26, 27, 22, 28, 28, 18, 11, 11, 11, 11, 7, 9, 5, 29, 29, 10, 30, 31, 10, 11, 27, 7, 11, 11, 9, 16, 10, 10, 13, 32, 10, 7, 27, 10, 10, 33, 7, 7, 9, 34, 10, 32, 21, 10, 1, 11, 35, 35, 18, 22, 7, 16, 16, 16, 30, 36, 36, 36, 37, 37, 11, 31, 38, 38, 2, 11, 7, 31, 39, 9, 40, 40, 31, 13, 7, 7, 33, 41, 41, 11, 42, 42, 18, 11, 43, 8, 44, 44, 6, 21, 11, 11, 0, 8, 2, 11, 8, 8, 8, 45, 11, 8, 11, 11, 2, 43, 43, 11, 39, 39, 46, 46, 0, 22, 11, 11, 22, 39, 47, 47, 22, 45, 48, 49, 49, 26, 11, 22, 0, 11, 22, 50, 50, 11, 22, 11, 42, 48, 39, 11, 22, 11, 11, 26, 31, 51, 51, 16, 7, 9, 12, 52, 52, 27, 53, 53, 54, 54, 55, 55, 16, 2, 22, 56, 11, 11, 34, 11, 32, 9, 57, 57, 58, 58, 25, 22, 0, 56, 59, 59, 9, 1, 45, 60, 60, 11, 22, 2, 9, 61, 61, 11, 11, 62, 62, 11, 26]\n",
    "# xcmp = map(lambda (a, b): a == b, itertools.product(x,y))\n",
    "# xcmp = [a == b for (a,b) in itertools.product(x,y)]\n",
    "xLen = len(x)\n",
    "yLen = len(y)\n",
    "if xLen == yLen:\n",
    "    print('list lengths are equal, proceeding...')\n",
    "valuesEqual = True\n",
    "for a in range(0, len(x)):\n",
    "    if x[a] == y[a]:\n",
    "        continue\n",
    "    else:\n",
    "        valuesEqual = False\n",
    "if not valuesEqual:\n",
    "    print('not all list values Match!!')\n",
    "else:\n",
    "    print('All values match!')\n",
    "# print(xcmp)\n",
    "'''\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 61)\n",
      "(87,)\n",
      "(21, 61)\n",
      "(21,)\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[ 0  0  0  0  1  2  2  3  4  5  4  6  1  0  2  4  7  8  8  9  3  7  7  0  0\n",
      "  0  4 10  0 10  0 11  0  8  5  5  3  6  7  5  7 11  7  0  4  4  9  2  0 10\n",
      "  7  7  0  2  9  0  9  2  0  4  0 10  4  0  0  9  2  7  0  5  5  1  0  9  7\n",
      "  3  0  0  0  0  7  5  9  0  9  2  0]\n",
      "[[1 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[0 1 0 2 2 0 3 3 4 5 3 3 5 6 4 4 7 8 3 8 3]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"]}]\n",
    "\n",
    "# KNearestNeighbors was used, but a different library may be applied later\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_knn_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# forest_clf_pred = forest_clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, y_knn_pred)\n",
    "# This accuracy score strictly tests the model, and may be subject to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  8 10  9  9 10  0  0  7  4  0  0  4  5  7  7  6  2  0  2  0]\n",
      "[0 1 0 2 2 0 3 3 4 5 3 3 5 6 4 4 7 8 3 8 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "forest_clf_pred = forest_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(Y_test, forest_clf_pred)\n",
    "print(forest_clf_pred)\n",
    "print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thor/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/thor/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.84782609,  0.92682927])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Commentary from John\n",
    "# 1) Cross-validation does exactly what it sounds like: it attempts to validate the results without worrying about overfitting, for a \"truly\" accurate score\n",
    "# 2) This is a bit of a \"hacked\" approach, because it's switching to Stochastic Gradient Descent (SGD) from KNN for the cross validation, but I plan on moving that direction anyway\n",
    "# 3) For the suspicious/worried, you can replace \"sgd_clf\" with \"knn_clf\" to also review the cross-validation result.\n",
    "# 4) Ignore the warning.  I'm using an outdated module from SciKit-Learn, if I ultimately use TensorFlow or Caffe it won't appear, and if I use SciKit-Learn I'll use an upadated module.\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "cross_val_score(sgd_clf, X_train, Y_train, cv=2, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
